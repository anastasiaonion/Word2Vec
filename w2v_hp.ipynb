{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import codecs \n",
    "import glob \n",
    "import multiprocessing \n",
    "import os \n",
    "import re \n",
    "import nltk \n",
    "import gensim.models.word2vec as w2v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\hp1.txt',\n",
       " 'data\\\\hp2.txt',\n",
       " 'data\\\\hp3.txt',\n",
       " 'data\\\\hp4.txt',\n",
       " 'data\\\\hp5.txt',\n",
       " 'data\\\\hp6.txt',\n",
       " 'data\\\\hp7.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_filenames = glob.glob(\"data/hp*.txt\")\n",
    "book_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Считывается data\\hp1.txt\n",
      "Сборка длиной 448811\n",
      "\n",
      "Считывается data\\hp2.txt\n",
      "Сборка длиной 947731\n",
      "\n",
      "Считывается data\\hp3.txt\n",
      "Сборка длиной 1569787\n",
      "\n",
      "Считывается data\\hp4.txt\n",
      "Сборка длиной 2690180\n",
      "\n",
      "Считывается data\\hp5.txt\n",
      "Сборка длиной 4190905\n",
      "\n",
      "Считывается data\\hp6.txt\n",
      "Сборка длиной 5182408\n",
      "\n",
      "Считывается data\\hp7.txt\n",
      "Сборка длиной 6321553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = \"\"\n",
    "for book_filename in book_filenames:\n",
    "    print('Считывается %s' % book_filename)\n",
    "    with codecs.open(book_filename,'r','utf-8') as file:\n",
    "        corpus_raw += file.read()\n",
    "    print('Сборка длиной %d' % len(corpus_raw))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 85779 предложений\n"
     ]
    }
   ],
   "source": [
    "#Разбиваем строку на предложения. Каждое предложение с новой строки\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "raw_sentences = tokenizer.tokenize(corpus_raw)\n",
    "print('Всего %d предложений' % len(raw_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Конвертируем предложения в массивы слов, убирая знаки пунктуации\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Проверка на пустые строки\n",
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if(len(raw_sentence) > 0):\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример:\n",
      "Предложение: Mr. Dursley hummed as he picked out his most boring tie for work, and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair.\n",
      "Получаем: ['Mr', 'Dursley', 'hummed', 'as', 'he', 'picked', 'out', 'his', 'most', 'boring', 'tie', 'for', 'work', 'and', 'Mrs', 'Dursley', 'gossiped', 'away', 'happily', 'as', 'she', 'wrestled', 'a', 'screaming', 'Dudley', 'into', 'his', 'high', 'chair']\n"
     ]
    }
   ],
   "source": [
    "print('Пример:')\n",
    "print('Предложение:', raw_sentences[13])\n",
    "print('Получаем:', sentence_to_wordlist(raw_sentences[13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 1120879 токенов\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print('Всего %d токенов' % token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Размер вектора\n",
    "num_features = 300\n",
    "\n",
    "#минимальное пороговое значение\n",
    "min_word_count = 3\n",
    "\n",
    "#количество потоков\n",
    "num_workers = multiprocessing.cpu_count() #возвращает к-во ядер процессора\n",
    "\n",
    "#размер окна\n",
    "context_size = 7\n",
    "\n",
    "#Downsample setting for frequent words\n",
    "downsampling = 1e-3 #Not see too many times the most frequent words...\n",
    "\n",
    "#Seed for the randomnessss, to make results reproducible\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hp2Vec = w2v.Word2Vec(sg=1,\n",
    "                           seed=seed,\n",
    "                           workers=num_workers,\n",
    "                           size=num_features,\n",
    "                           min_count=min_word_count,\n",
    "                           window=context_size,\n",
    "                           sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hp2Vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина словаря Word2Vec: 85779\n"
     ]
    }
   ],
   "source": [
    "print('Длина словаря Word2Vec: %d' % hp2Vec.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4245335"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp2Vec.train(sentences=sentences,total_examples=hp2Vec.corpus_count,epochs=hp2Vec.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lupin', 0.7298069000244141),\n",
       " ('Slughorn', 0.7228484153747559),\n",
       " ('Firenze', 0.6937481164932251),\n",
       " ('Snape', 0.67584228515625),\n",
       " ('Fudge', 0.6648882627487183),\n",
       " ('headmaster', 0.6583600640296936),\n",
       " ('Riddle', 0.6537696123123169),\n",
       " ('Scrimgeour', 0.6453474760055542),\n",
       " ('Quirrell', 0.6449023485183716),\n",
       " ('Aberforth', 0.6334937810897827)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp2Vec.most_similar(\"Dumbledore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lucius', 0.7676020860671997),\n",
       " ('Greyback', 0.7372422218322754),\n",
       " ('Narcissa', 0.7320736646652222),\n",
       " ('Zabini', 0.7319016456604004),\n",
       " ('Yaxley', 0.7314563393592834),\n",
       " ('encouragingly', 0.728295087814331),\n",
       " ('resentfully', 0.7251095175743103),\n",
       " ('Travers', 0.7247826457023621),\n",
       " ('smirking', 0.7217026948928833),\n",
       " ('Amos', 0.7152628302574158)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp2Vec.most_similar(positive=['Draco', 'Harry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Severus'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp2Vec.doesnt_match('Harry, Ron, Hermione, Severus'.split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
