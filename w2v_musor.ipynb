{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import codecs \n",
    "import glob \n",
    "import multiprocessing \n",
    "import os \n",
    "import re \n",
    "import nltk \n",
    "import gensim.models.word2vec as w2v\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texts\\\\1.txt',\n",
       " 'texts\\\\10.txt',\n",
       " 'texts\\\\11.txt',\n",
       " 'texts\\\\12.txt',\n",
       " 'texts\\\\13.txt',\n",
       " 'texts\\\\14.txt',\n",
       " 'texts\\\\15.txt',\n",
       " 'texts\\\\16.txt',\n",
       " 'texts\\\\17.txt',\n",
       " 'texts\\\\18.txt',\n",
       " 'texts\\\\19.txt',\n",
       " 'texts\\\\2.txt',\n",
       " 'texts\\\\20.txt',\n",
       " 'texts\\\\3.txt',\n",
       " 'texts\\\\4.txt',\n",
       " 'texts\\\\5.txt',\n",
       " 'texts\\\\6.txt',\n",
       " 'texts\\\\7.txt',\n",
       " 'texts\\\\8.txt',\n",
       " 'texts\\\\9.txt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "#Загрузка текста\n",
    "texts = sorted(glob.glob(\"texts/*.txt\"))\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['а', 'бы', 'в', 'во', 'вот', 'для', 'до', 'если', 'же', 'за', 'и', 'из', 'или', 'к', 'ко', 'между', 'на', 'над', 'но', 'о', 'об', 'около', 'от', 'по', 'под', 'при', 'про', 'с', 'среди', 'то', 'у', 'чтобы', 'их', 'при', 'таких', 'также', 'как', 'что', 'того', 'не', 'москва', 'москве', 'вам', 'вас', 'вам', 'вас', 'москвы', 'так', 'м', 'его', 'нас', 'все', 'это', 'наша', 'объ']\n"
     ]
    }
   ],
   "source": [
    "#Загрузка стоп-слов\n",
    "with codecs.open('stopwords.txt', 'r', 'utf-8') as file:\n",
    "    words = file.read()\n",
    "    raw_words = tokenizer.tokenize(words)\n",
    "    clean = (re.sub(\"[^а-яА-Я]\", \" \", raw_words[0])).lower()\n",
    "    stopwords = clean.split()\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Считывается texts\\1.txt\n",
      "Сборка длиной 3605 символов\n",
      "\n",
      "Считывается texts\\10.txt\n",
      "Сборка длиной 6031 символов\n",
      "\n",
      "Считывается texts\\11.txt\n",
      "Сборка длиной 9343 символов\n",
      "\n",
      "Считывается texts\\12.txt\n",
      "Сборка длиной 12382 символов\n",
      "\n",
      "Считывается texts\\13.txt\n",
      "Сборка длиной 14669 символов\n",
      "\n",
      "Считывается texts\\14.txt\n",
      "Сборка длиной 16154 символов\n",
      "\n",
      "Считывается texts\\15.txt\n",
      "Сборка длиной 18538 символов\n",
      "\n",
      "Считывается texts\\16.txt\n",
      "Сборка длиной 20989 символов\n",
      "\n",
      "Считывается texts\\17.txt\n",
      "Сборка длиной 20989 символов\n",
      "\n",
      "Считывается texts\\18.txt\n",
      "Сборка длиной 21790 символов\n",
      "\n",
      "Считывается texts\\19.txt\n",
      "Сборка длиной 26436 символов\n",
      "\n",
      "Считывается texts\\2.txt\n",
      "Сборка длиной 31316 символов\n",
      "\n",
      "Считывается texts\\20.txt\n",
      "Сборка длиной 80660 символов\n",
      "\n",
      "Считывается texts\\3.txt\n",
      "Сборка длиной 84013 символов\n",
      "\n",
      "Считывается texts\\4.txt\n",
      "Сборка длиной 88532 символов\n",
      "\n",
      "Считывается texts\\5.txt\n",
      "Сборка длиной 92922 символов\n",
      "\n",
      "Считывается texts\\6.txt\n",
      "Сборка длиной 96928 символов\n",
      "\n",
      "Считывается texts\\7.txt\n",
      "Сборка длиной 99507 символов\n",
      "\n",
      "Считывается texts\\8.txt\n",
      "Сборка длиной 102182 символов\n",
      "\n",
      "Считывается texts\\9.txt\n",
      "Сборка длиной 105055 символов\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Все тексты в одну большую строку\n",
    "corpus_raw = \"\"\n",
    "for text in texts:\n",
    "    print('Считывается %s' % text)\n",
    "    with codecs.open(text,'r','utf-8') as file:\n",
    "        corpus_raw += file.read()\n",
    "    print('Сборка длиной %d символов' % len(corpus_raw))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 736 предложений\n"
     ]
    }
   ],
   "source": [
    "#Разбиваем строку на предложения. Каждое предложение с новой строки\n",
    "raw_sentences = tokenizer.tokenize(corpus_raw)\n",
    "print('Всего %d предложений' % len(raw_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean_data = []\n",
    "    clean = (re.sub(\"[^а-яА-Яa-zA-Z]\",\" \", raw)).lower()\n",
    "    words = clean.split()\n",
    "    for word in words:\n",
    "        if np.isin(word, stopwords) == False and len(word)>2:\n",
    "            clean_data.append(word)\n",
    "    return(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if(len(raw_sentence) > 0):\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример:\n",
      "Предложение: Стоимость услуги в таком случае рассчитывается, исходя из состава отходов, их количества и расстояния до ближайшего места захоронения.\n",
      "Получаем: ['стоимость', 'услуги', 'таком', 'случае', 'рассчитывается', 'исходя', 'состава', 'отходов', 'количества', 'расстояния', 'ближайшего', 'места', 'захоронения']\n"
     ]
    }
   ],
   "source": [
    "print('Пример:')\n",
    "print('Предложение:', raw_sentences[13])\n",
    "print('Получаем:', sentence_to_wordlist(raw_sentences[13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 10002 токенов\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print('Всего %d токенов' % token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Размер вектора\n",
    "num_features = 300\n",
    "\n",
    "#минимальное пороговое значение\n",
    "min_word_count = 3\n",
    "\n",
    "#количество потоков\n",
    "num_workers = multiprocessing.cpu_count() #возвращает к-во ядер процессора\n",
    "\n",
    "#размер окна\n",
    "context_size = 7\n",
    "\n",
    "#Downsample setting for frequent words\n",
    "downsampling = 1e-3 #Not see too many times the most frequent words...\n",
    "\n",
    "#Seed for the randomnessss, to make results reproducible\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2Vec = w2v.Word2Vec(sg=1,\n",
    "                           seed=seed,\n",
    "                           workers=num_workers,\n",
    "                           size=num_features,\n",
    "                           min_count=min_word_count,\n",
    "                           window=context_size,\n",
    "                           sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2Vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина словаря Word2Vec: 736\n"
     ]
    }
   ],
   "source": [
    "print('Длина словаря Word2Vec: %d' % word2Vec.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26622"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Тренируем модель\n",
    "word2Vec.train(sentences=sentences,total_examples=word2Vec.corpus_count,epochs=word2Vec.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраняемся\n",
    "word2Vec.save('word2Vec.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('услуг', 0.9998680949211121),\n",
       " ('только', 0.9998652338981628),\n",
       " ('отходы', 0.9998636841773987),\n",
       " ('снег', 0.9998620748519897),\n",
       " ('предоставляем', 0.9998615980148315),\n",
       " ('отходов', 0.9998572468757629),\n",
       " ('техники', 0.9998534917831421),\n",
       " ('утилизации', 0.999853253364563),\n",
       " ('можно', 0.9998525381088257),\n",
       " ('позволяет', 0.9998493194580078)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Vec.most_similar(\"мусор\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
